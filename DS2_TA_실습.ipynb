{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2e1M7BS1ID66",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# DS<sup>2</sup> Probability, Statistics and Bayesian Statistics : Python 실습\n",
    "\n",
    "TA : 김당찬(dang112@snu.ac.kr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 모듈 소개  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mBUoT9IVIApF",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "1. `scipy.stats`\n",
    "\n",
    "- `scipy` 패키지는 수치해석, 통계, 신호처리 등 다양한 수학적 기능을 제공하는 패키지입니다. `scipy` 패키지 안의 `stats` 모듈은 확률분포와 통계에 관련된 함수들을 제공합니다.\n",
    "- `scipy.stats` 패키지 안의 함수로 여러가지 분포함수들을 사용할 수 있습니다. (`binom`, `uniform`, `norm`, `chi2`, `t`, `f` 등)   \n",
    "  \n",
    "2. `numpy`\n",
    "\n",
    "- 벡터, 행렬 등의 표현 및 빠른 계산을 위해서 `numpy` 패키지가 필요합니다. \n",
    "- 강의에는 주로 수의 제곱근형태(sqrt), 수열(arange), 나열(array),올림(ceil) 이나 집단의 평균(mean), 분산(var), 표준편차(std) 등을 구하는 데에 주로 사용합니다.\n",
    "  \n",
    "3. `matplotlib.pyplot`\n",
    "\n",
    "- `matplotlib` 패키지는 시각화를 위해 사용되는 파이썬의 대표적인 라이브러리입니다. \n",
    "- `matplotlib.pyplot` 모듈은 그래프를 그리기 위한 다양한 함수들을 제공합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6JcCz2fsHN4e",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "`matplotlib.pyplot` 모듈의 함수들 중 자주 사용되는 함수들은 다음과 같습니다.\n",
    "\n",
    "|     함수     | 설명 |\n",
    "|----------|-----------------|\n",
    "|`figure()` | matplotlib 에서 그래프가 들어가는 영역을 의미한다.| \n",
    "|`plot()`   |그래프를 그려준다.           | \n",
    "|`subplots()` |subplot들을 포함하는 figure를 생성해준다.            |\n",
    "|`legend()`|범례를 그려준다.|\n",
    "|`show()`|그래프를 화면에 보여준다.|\n",
    "|`xlabel()`|x축에 라벨을 출력한다.|\n",
    "|`ylabel()`|y축에 라벨을 출력한다.|\n",
    "|`title()`|타이틀을 출력한다.|\n",
    "|`xlim()`|x축의 상한/하한 값을 설정한다.|\n",
    "|`ylim()`|y축의 상한/하한 값을 설정한다.|\n",
    "|`subplot()`|subplot을 지정한다.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nf_AzsrvdHVc",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scienceplots\n",
    "\n",
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "plt.style.use('science')\n",
    "\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.stats import uniform, norm, invgamma\n",
    "\n",
    "import arviz as az\n",
    "import pymc as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Package versions\n",
    "print('Running on Python v{}'.format(sys.version))\n",
    "print('Running on PyMC3 v{}'.format(pm.__version__))\n",
    "print('Running on ArviZ v{}'.format(az.__version__))\n",
    "print('Running on NumPy v{}'.format(np.__version__))\n",
    "print('Running on Pandas v{}'.format(pd.__version__))\n",
    "print('Running on SciPy v{}'.format(scipy.__version__))\n",
    "print('Running on Seaborn v{}'.format(sns.__version__))\n",
    "print('Running on Matplotlib v{}'.format(plt.matplotlib.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sbkWXvAYIPRn",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 표본추출 (Sampling)\n",
    "\n",
    "• 모집단 (population): 정보를 얻고자 하는 대상이 되는 집단 전체\n",
    "\n",
    "• 표본 (Sample): 모집단에서 추출한 부분집합\n",
    "\n",
    "▷ 유한모집단에서 랜덤표본 (Random Sample): 단순 랜덤 비복원추출로 뽑은 표본\n",
    "\n",
    "e.g.\n",
    "\n",
    "$$ X_1, X_2, \\cdots, X_n \\in \\{1, 2, \\cdots, N\\} $$\n",
    "\n",
    "▷ 무한모집단에서 랜덤표본: 동일한 분포(모집단의 분포)를 따르는 독립인 확률변수들\n",
    "\n",
    "e.g.\n",
    "\n",
    "$$ X_1, X_2, \\cdots, X_n \\sim F $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "72p17D_CIPT9",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 일반적인 분포로부터의 난수 생성\n",
    "\n",
    "- `scipy.stats` 모듈이나 `np.random` 모듈을 이용하여 다양한 분포로부터 난수를 생성할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 균등분포\n",
    "다음은 균일분포 $U(0, 1)$에서 크기가 10인 표본을 추출하는 코드입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hgBzQOuuUErC",
    "outputId": "db2e5e83-55ac-4e8f-9217-c2521a3b1fd4",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "uniform.rvs(0,1, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Numpy\n",
    "np.random.seed(0)\n",
    "np.random.uniform(0,1,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 정규분포\n",
    "다음은 정규분포 $N(0, 1)$에서 크기가 10인 표본을 추출하는 코드입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "681JLUEGUEth",
    "outputId": "d9aef092-affb-4dc2-da59-ff102bcd4da4",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "norm.rvs(0,1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "np.random.normal(0,1,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aJ1bYXJBUaxj",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 난수의 히스토그램\n",
    "표준정규분포 $N(0, 1)$에서 크기가 $10000$인 표본을 추출해 히스토그램을 그려보면 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "y_6i8Ma2UEv3",
    "outputId": "95ea1e1a-0dd3-4e58-f39b-1559f88e6d31",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "np.random.seed(0)\n",
    "norm_rv = norm.rvs(0,1, 10000)\n",
    "plt.hist(norm_rv, 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "확률밀도함수(pdf)와 히스토그램을 비교해보면 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "\n",
    "xs = np.linspace(-4, 4, 1000)\n",
    "\n",
    "ax.plot(xs, norm.pdf(xs), lw=1.0, label='norm pdf')\n",
    "ax.hist(norm_rv, bins=100, density=True, alpha=0.5, label='norm rvs')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tji5vtE-VNAO",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 기각 샘플링 (Rejection Sampling)\n",
    "\n",
    "`scipy, numpy` 등의 패키지에 내장된 대표적인 확률분포로부터 샘플링 하는 것은 간단합니다. 그러나 다음과 같이 임의로 설정된 복잡한 확률분포에 대한 샘플링 문제를 해결하기 위해서는 다른 방법을 이용해야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y6SpekToVY2l",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "실습자료에 예시로 제시된\n",
    "$$\n",
    "f(x)=0.3 \\exp \\left(-0.1 x^2\\right)+0.7 \\exp \\left(-0.2(x-10)^2\\right)\n",
    "$$\n",
    "를 따르는 $X$를 샘플링하는 문제를 생각해보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "이러한 경우, rejection sampling을 이용하여 샘플링을 시행할 수 있습니다.\n",
    "\n",
    "제안분포로 사용될 $g$는 다음과 같습니다. ($f$보다 난수생성이 쉬운 분포 e.g. Uniform distribution)\n",
    "$$\n",
    "g(X) = \\frac{1}{24}(-7<X<17) \\sim \\text{Unif}(-7,17)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "trApV-gLUEyQ",
    "outputId": "05e1a09b-caa3-4715-bdcc-2f6c3286df67",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# 확률밀도함수 그리기 \n",
    "\n",
    "def f(x):\n",
    "    return 0.3*(np.exp(-0.2*x**2)) + 0.7*(np.exp(-0.2*(x-10)**2))\n",
    "\n",
    "xs = np.linspace(-10, 20, 10000)\n",
    "fxs = f(xs)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(xs, fxs, label=\"PDF\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "-Gk26lacUE0q",
    "outputId": "15dc43e7-91c2-4232-98ae-ffa6c6b3ec4a",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# 제안분포 그리기\n",
    "def g(x):\n",
    "    return uniform(loc=-7, scale=24).pdf(x)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(xs, fxs, label=\"Target\")\n",
    "plt.plot(xs, g(xs), label=\"Proposal\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KNBus5a2XVGB",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "$\\beta=\\dfrac{1}{24*0.7}$으로 설정하면, 다음과 같이 upper envelope를 구할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "v9Z1-pB3UNUD",
    "outputId": "f6499e48-13f5-4a2c-b3b4-68e7ecdc9dc9",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "beta = 1 / (24 * 0.7)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(xs, fxs, label=\"Target\")\n",
    "plt.plot(xs, g(xs) / beta, label=\"Proposal\")\n",
    "plt.ylim(0,1.)\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kGU3bYLMXh4j",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "이제 Rejection sampling 일고리즘으로부터 난수를 생성해보자.\n",
    "\n",
    "(1) $g$로부터 $X$를 생성한다.\n",
    "\n",
    "(2) $U(0, 1)$로 부터 $U$ 를 생성한다.\n",
    "\n",
    "(3) 만약 $Ug(X) ≤ βf(X)$를 만족하면 $X$를 $f$ 에서 생성된 난수라고 받아들인다. 만족하지 않으면 아니라고 받아들인다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TlPdKW1VUNPI",
    "outputId": "9b959f77-eac5-4891-c857-1c84769da55c",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "n = 10000 # 반복 횟수\n",
    "\n",
    "# Step 1 : g로부터 샘플 생성\n",
    "\n",
    "Xs = uniform.rvs(-7, 24, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Step 2\n",
    "Us = uniform.rvs(0,1, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Step 3\n",
    "accept = np.where(g(Xs) * Us < beta * f(Xs))\n",
    "\n",
    "samples = Xs[accept]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "vC7VhExNX0-U",
    "outputId": "496db9b2-8225-4966-c800-6bbc08429242",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Plot\n",
    "fig, ax = plt.subplots(1,1, figsize=(6, 6))\n",
    "\n",
    "ax.hist(samples, bins=50, density=True, label='sample')\n",
    "ax.plot(xs, fxs, label='true')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.integrate import quad\n",
    "\n",
    "quad(f, -np.inf, np.inf)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Plot after normalization\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(6, 6))\n",
    "\n",
    "ax.hist(samples, bins=50, density=True, label='sample')\n",
    "ax.plot(xs, fxs / quad(f, -np.inf, np.inf)[0], label='true')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Note : `np.random.seed()` 등 random number seed를 고정시키고자 할 때, 각각의 $X,U$ 등을 생성할 때마다 seed를 고정시키게 되면 두 변수의 상관관계가 생길 수 있음에 주의하자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "Xs = uniform.rvs(-7, 24, n)\n",
    "\n",
    "np.random.seed(0)\n",
    "Us = uniform.rvs(0,1, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Step 2\n",
    "accept = np.where(g(Xs) * Us < beta * f(Xs))\n",
    "samples = Xs[accept]\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "ax.hist(samples, bins=50, density=True, label='sample')\n",
    "ax.plot(xs, fxs / quad(f, -7, 17)[0], label='true')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Markov Chain Monte Carlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQMR6blUZC57",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Metropolis-Hastings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 목적 \n",
    "- 원하는 분포 $P(x)$ 에서 direct sampling이 어려울 때, 그 분포를 따르는 random sample을 얻기 위해서 시행하는 알고리즘\n",
    "- Approximate the desired distribution (histogram)\n",
    "- Compute an integral (ex : 기댓값 계산)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Algorithm\n",
    "\n",
    "1. 초기값 설정 $x_0$, $\\;t=0$\n",
    "\n",
    "2. 제안분포(or jumping kernel) $g(\\cdot)$에서 다음 단계의 후보값 $x^{\\prime}$을 랜덤하게 뽑는다.\n",
    "\n",
    "3. 다음 **Acceptance probability**를 계산한다.\n",
    "\n",
    "$$\n",
    "\\left(A\\left(x^{\\prime}, x_{t}\\right)=\\min \\left(1, \\frac{P\\left(x^{\\prime}\\right)}{P\\left(x_{t}\\right)} \\frac{g\\left(x_{t} | x^{\\prime}\\right)}{g\\left(x^{\\prime} | x_{t}\\right)}\\right) \\right)\n",
    "$$\n",
    "\n",
    "4. Accept of Reject 결정 : $x^{t+1} = x^{\\prime}$ with probability $A(x^{\\prime}, x_t)$\n",
    "\n",
    "$$\n",
    "\\begin{array}{l}\n",
    "{\\text { [1] generate a uniform random number } u \\in[0,1] \\text { ; }} \\\\ \n",
    "{\\text { [2] if } u \\leq A\\left(x^{\\prime}, x_{t}\\right), \\text { accept the new state and set } x_{t+1}=x^{\\prime} \\text { ; }} \\\\ \n",
    "{\\text { [3] if } u>A\\left(x^{\\prime}, x_{t}\\right), \\text { reject the new state, and copy the old state forward } x_{t+1}=x_{t} \\text { ; }}\\end{array}\n",
    "$$\n",
    "\n",
    "5. Set $t = t+1$, step 2-5를 반복한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZTBQiDdZC3G",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- 다음 상태로 나아갈지에 대한 여부를 acceptance probability에 근거하여 결정하는 알고리즘  \n",
    "\n",
    "> Sometimes accepting the moves and sometimes remaining in place\n",
    "\n",
    "- Acceptance ratio $\\alpha$의 의미 : 새로운 후보값이 현재값에 비해 $P(x)$에서 나온 sample일 가능성 (>1 : 후보값이 현재값보다 원하는 분포에서 나왔을 가능성이 더 높다.) \n",
    "\n",
    "- 그러므로, 단계가 반복될수록 $P(x)$의 high-density regions에서 sample을 뽑게 된다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Previous Example\n",
    "\n",
    "- 이전 기각 샘플링 예시에서 $(-7,17)$ 외 영역에서의 샘플링은 이루어지지 않았습니다.\n",
    "$$\n",
    "f(x)=0.3 \\exp \\left(-0.2 x^2\\right)+0.7 \\exp \\left(-0.2(x-10)^2\\right)\n",
    "$$\n",
    "\n",
    "- 이를 Metropolis-Hastings 알고리즘을 이용하여 샘플링해 보겠습니다.\n",
    "- 제안분포로는 정규분포를 사용합니다.\n",
    "$$g(x^\\prime|x_t) = N(x_t, 1^2)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Metropolis-Hastings\n",
    "\n",
    "def MH(seed, n):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    x = np.zeros(n)\n",
    "    x[0] = 5 # 초기값\n",
    "\n",
    "    for i in range(1, n):\n",
    "        z = norm.rvs(x[i-1], 1) # 제안분포\n",
    "        r = min(1, f(z) / f(x[i-1])) # acceptance ratio\n",
    "        if uniform.rvs(0,1) < r:\n",
    "            x[i] = z\n",
    "        else:\n",
    "            x[i] = x[i-1]\n",
    "\n",
    "    return x\n",
    "\n",
    "x = MH(30, 100000)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "ax.plot(x)\n",
    "ax.set_title('MH of $f(x) = 0.3N(0,2.5) + 0.7N(10,2.5)$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Burn-in 제외, histogram plot\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "ax.hist(x[10000:], bins=50, density=True, label='sample')\n",
    "ax.plot(xs, fxs / quad(f, -7, 17)[0], label='true')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "MCMC는 seed 설정에 의해 Markov chain이 생성되므로, sample이 충분하지 않다면 seed를 변화시킴에 따라 결과가 달라질 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "for i, seed in enumerate([0, 10, 20]):\n",
    "    x = MH(seed, 10000)\n",
    "    # trace plot\n",
    "    axes[0, i].plot(x)\n",
    "    axes[0, i].set_title('seed = {}'.format(seed))\n",
    "    # histogram\n",
    "    axes[1, i].hist(x[9000:], bins=50, density=True, label='sample')\n",
    "    axes[1, i].plot(xs, fxs / quad(f, -np.inf, np.inf)[0], label='true')\n",
    "    axes[1, i].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KoHY7nXWZCuj",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 예시 1\n",
    "\n",
    "어느 공정에 하루동안 투입되는 화학물질의 양의 100일간 데이터가 있다. 이 데이터는 정규분포를 따르고, 과거 정보에 의하면 표준편차가 1이라고 알려져있다. 이 때 화학물질이 투입되는 일일 평균양에 대한 사후분포를 M-H 방법으로 구해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_B2yhskNelSB",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "\n",
    "- $Y_1, ...,Y_{100} \\sim i.i.d \\; N(\\theta,1)$의 데이터가 존재  ($\\theta = 3$)\n",
    "\n",
    "\n",
    "- $\\theta$의 사전분포 :\n",
    "$$\\pi_0(\\theta)=\\frac{1}{\\pi(1+\\theta^2)}$$\n",
    "\n",
    "\n",
    "- 사후분포 : \n",
    "$$\n",
    "\\begin{aligned} \\pi\\left(\\theta | Y_{1}, \\cdots, Y_{n}\\right) \\; & \\propto \\exp \\left(-\\frac{\\sum_{i=1}^{n}\\left(Y_{i}-\\theta\\right)^{2}}{2}\\right) \\times \\frac{1}{1+\\theta^{2}} \\\\ & \\propto \\exp \\left(-\\frac{n(\\theta-\\overline{Y})^{2}}{2}\\right) \\times \\frac{1}{1+\\theta^{2}} \\end{aligned}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "- 제안분포 : \n",
    "$$q\\left(\\theta | \\theta^{*}\\right)=\\frac{1}{\\sqrt{2 \\pi n^{-1}}} e^{-\\frac{(\\theta-\\overline{Y})^{2}}{2 / n}}, \\text { i.e. } N\\left(\\overline{Y}, \\frac{1}{n}\\right)$$\n",
    "\n",
    "\n",
    "- acceptance ratio $\\alpha$ : \n",
    "$$\n",
    "\\begin{aligned} \\alpha\\left(\\theta^{(i-1)}, \\tilde{\\theta}\\right) &=\\min \\left(1, \\frac{\\pi\\left(\\tilde{\\theta} | Y_{1}, \\cdots, Y_{n}\\right) q\\left(\\theta^{(i-1)} | \\tilde{\\theta}\\right)}{\\pi\\left(\\theta^{(i-1)} | Y_{1}, \\cdots, Y_{n}\\right) q\\left(\\tilde{\\theta} | \\theta^{(i-1)}\\right)}\\right) \\\\ &=\\min \\left(1, \\frac{1+\\left(\\theta^{(i-1)}\\right)^{2}}{1+(\\tilde{\\theta})^{2}}\\right) \\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P3sO_7qgX3WR",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "\n",
    "# Observation of 100 individual, with mean = 3 and scale = 1 (실습에서는 데이터를 generate해서 사용하자.)\n",
    "\n",
    "n = 100\n",
    "observation = norm.rvs(3, 1, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 891
    },
    "id": "G_yrGwOXX3Tn",
    "outputId": "7b76a360-899a-4f40-d31d-440ce8656249",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# 관측한 data의 histogram\n",
    "fig, ax = plt.subplots(1,1, figsize=(6,6))\n",
    "sns.distplot(observation, ax=ax, kde=True, bins=20)\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"100 sample from a pop of 10,000 with $\\mu=3, \\sigma=1$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p_kV3gOFX3Be",
    "outputId": "25391688-f0f7-4769-b6f7-c6ecf2f4e3de",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "mu_obs = observation.mean()\n",
    "mu_obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b96kIExMZZ79",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# setting\n",
    "para_init = 1\n",
    "iterations = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "### Metropolis-Hastings algorithm ###\n",
    "\n",
    "theta = []\n",
    "theta_old = para_init\n",
    "\n",
    "for i in range(iterations):\n",
    "    theta_new = norm.rvs(mu_obs, 1/n, 1)[0] # 제안분포로부터 샘플링\n",
    "    log_alpha = min(np.log(1), np.log(1+theta_old**2)-np.log(1+theta_new**2)) # log of acceptance probability\n",
    "    r = uniform.rvs(0, 1, 1)[0]\n",
    "    if np.log(r) < log_alpha:\n",
    "        theta_old = theta_new\n",
    "        theta.append(theta_new)\n",
    "    else :\n",
    "        theta.append(theta_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T-_LnQitZZ5c",
    "outputId": "cd1818dc-8072-4f0c-9e93-0b81a616c087",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# output\n",
    "len(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 891
    },
    "id": "zJOu7VZtZZ2-",
    "outputId": "fbb6a553-6fc0-46ed-f6e3-30647c4338a3",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# 앞의 9000개는 burn-in period, 나머지 1000개 샘플로 정상분포 추정\n",
    "theta_burned = theta[9000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# histogram of MCMC samples\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.hist(np.array(theta_burned), bins = 50)\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of theta\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 548
    },
    "id": "WXgO3YHTZdX8",
    "outputId": "c036ffdc-d4fb-41d6-aee0-17b0c0b39353",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# trace plot\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(theta)\n",
    "plt.xlabel(\"iter\")\n",
    "plt.ylabel(\"theta\")\n",
    "plt.title(\"Markov chain by M-H of theta\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 491
    },
    "id": "ZpeKe_zkZdVw",
    "outputId": "bcedd663-48b0-474a-df80-6b35ba802d8b",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(np.linspace(9001, 10000, 1000), np.array(theta_burned))\n",
    "plt.xlabel(\"iter\")\n",
    "plt.ylabel(\"theta\")\n",
    "plt.title(\"Markov chain by M-H of theta after burn-in period\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vDv1VpCEZdTg",
    "outputId": "5539f0a7-d31d-4729-de9f-563edf12da07",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# 사후기댓값의 추정량\n",
    "print(np.mean(theta_burned))\n",
    "# 사후중앙값의 추정량\n",
    "print(np.median(theta_burned))\n",
    "# credible interval\n",
    "print(round(np.percentile(theta_burned, 2.5), 4)) # 2.5% 분위수\n",
    "print(round(np.percentile(theta_burned, 97.5), 4)) #97.5% 분위수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AzJpr8gpZnv8",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 깁스 샘플링(Gibbs Sampling)\n",
    "### 특징\n",
    "- 2차원 이상의 모수에 대한 사후분포를 각 모수에 대한 조건부 사후분포의 집합으로 나타낸다.\n",
    "\n",
    "    ex) 2차원 모수 $\\Theta=(\\mu, \\sigma)$에 대한 사후분포 $\\pi(\\mu, \\sigma | Y_{1}, \\cdots, Y_{n})$를 $\\{\\pi(\\mu| \\sigma, Y_{1}, \\cdots, Y_{n}),\\; \\pi(\\sigma | \\mu, Y_{1}, \\cdots, Y_{n})\\}$으로 나타낸다. \n",
    "\n",
    "- joint distribution을 구하기 어려울 때나 이 분포에서 바로 sampling하기 어려울 때 각 모수에 대한 conditional distribution을 안다면 적용 가능\n",
    "\n",
    "- algorithm은 다른 변수의 현재값에 따라 각 변수의 분포에서 차례로 샘플을 생성한다. (즉, 생성된 samplie sequence는 Markov Chain을 구성)\n",
    "\n",
    "- Markov Chain의 정상분포는 joint distribution (사후분포)\n",
    "\n",
    "$$ $$\n",
    "\n",
    "참고) Conditional distribution과 Joint distribution의 관계 \n",
    "\n",
    ": 한 변수에 대한 conditional distribution(다른 변수들은 고정된 상태)은 joint distribution에 비례한다.\n",
    "\n",
    "<br>\n",
    "\n",
    "$$p\\left(x_{j} | x_{1}, \\ldots, x_{j-1}, x_{j+1}, \\ldots, x_{n}\\right)=\\frac{p\\left(x_{1}, \\ldots, x_{n}\\right)}{p\\left(x_{1}, \\ldots, x_{j-1}, x_{j+1}, \\ldots, x_{n}\\right)} \\propto p\\left(x_{1}, \\ldots, x_{n}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PJwajFxBZntO",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Example 2\n",
    "어떤 공장의 각 Lot별 생산된 wafer들의 수율(%)은 정규분포를 따른다고 한다. 50개의 Lot을 랜덤 추출하여 Lot의 수율에 대한 평균과 분산을 Gibbs Sampling 방법으로 베이지안 추정을 해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zu7DIoSvZt0t",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- $X_{1}, \\cdots, X_{50} \\overset{iid}{\\sim} N\\left(\\mu, \\sigma^{2}\\right) $의 데이터가 존재 ($\\mu = 95(\\%), \\sigma^2 = 1(\\%)$)\n",
    "\n",
    "- 목적 : $\\mu, \\sigma^2$ 추정하는 것\n",
    "\n",
    "- 사전분포 : $\\pi(\\mu) \\propto 1 \\;\\; \\& \\;\\; \\pi(\\sigma^2) \\propto \\frac{1}{\\sigma^2}$\n",
    "\n",
    "- 조건부 사후분포 :\n",
    " $$\\begin{aligned} \\mu | \\boldsymbol{X}, \\sigma^{2} & \\sim N\\left(\\overline{X}, \\frac{\\sigma^{2}}{n}\\right) \\\\ \\sigma^{2} | \\boldsymbol{X}, \\mu & \\sim \\text { IGamma }\\left(\\frac{n}{2}, \\frac{1}{2} \\sum_{i=1}^{n}\\left(X_{i}-\\mu\\right)^{2}\\right) \\end{aligned}$$\n",
    " \n",
    "- Algorithm\n",
    "\n",
    "$$\n",
    "\\displaystyle\n",
    "\\begin{array}{l}\n",
    "{\\text { [1] Initialize } \\left( \\mu^{(0)}, \\sigma^{2(0)}\\right)}\\\\\\\\\n",
    "{ \\text{For s=1  to N}} : \\\\\\\\\n",
    "{ \\text { [2] } \\mu^{(s)} \\sim N\\left(\\overline{X}, \\frac{\\sigma^{2(s-1)}}{n}\\right)}\\\\ \n",
    "{ \\text{ [3] }  \\sigma^{2(s)} \\sim \\text { InvGamma }\\left(\\dfrac{n}{2}, \\dfrac{1}{2} \\sum_{i=1}^{n} \\left(X_{i}-\\mu^{(s)}\\right)^{2}\\right)} \\end{array}\n",
    "$$\n",
    "\n",
    "초기값으로 $\\mu^{(0)} = 95\\%, \\sigma^{2(0)} = 0.3 \\%$로 놓고, $N = 10,000$개의 Gibbs sampler $\\left(\\left(\\mu^{(s)}, \\sigma^{2(s)}\\right), s=1, \\cdots, 10000\\right)$를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 891
    },
    "id": "BFLT49AVZtDf",
    "outputId": "6e41e189-ab8d-460d-d11d-487d35fa2536",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# 평균 95, 표준편차 1인 정규분포를 따르는 50개의 데이터\n",
    "n = 50\n",
    "obs = norm.rvs(95, 1, n)\n",
    "\n",
    "# 관측한 data의 histogram\n",
    "plt.figure(figsize = (6, 6))\n",
    "plt.hist(obs, bins = 10)\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of 50 obs with mu=95, sigma=1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WOUvMJ_8ZzIj",
    "outputId": "1969677a-0cde-4518-b259-f5322e982018",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "xbar = obs.mean()\n",
    "xbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L3M0eA9TZzFt",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# setting initial values\n",
    "mu_init = 95\n",
    "sigma2_init = 0.3\n",
    "N = 10000\n",
    "\n",
    "# conditional distribution 함수 정의\n",
    "def mu_given_sigma2(s2):\n",
    "    # s2는 i-1번째 분산 값\n",
    "    return norm.rvs(xbar, np.sqrt(s2)/np.sqrt(n))\n",
    "\n",
    "def sigma2_given_mu(m):\n",
    "    # m은 i번째 update된 mu값\n",
    "    beta = sum((obs-m)**2)/2\n",
    "    return invgamma.rvs(a = n/2, scale = beta, size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xrmjt19AZzCf",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "### Gibbs Sampling algorithm ###\n",
    "mu = []\n",
    "sigma2 = []\n",
    "mu_old = mu_init\n",
    "sigma2_old = sigma2_init\n",
    "\n",
    "for i in range(N):\n",
    "    mu_new = mu_given_sigma2(sigma2_old)\n",
    "    sigma2_new = sigma2_given_mu(mu_new)\n",
    "    mu_old = mu_new\n",
    "    sigma2_old = sigma2_new\n",
    "    mu.append(mu_new)\n",
    "    sigma2.append(sigma2_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "uNku-1kKZ36Q",
    "outputId": "080431dd-fc96-4a0f-9a35-187d059b1ab8",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# 앞의 5000개는 burn-in period, 나머지 5000개로 정상분포 추정\n",
    "mu_burn = mu[5000:] \n",
    "sigma2_burn = sigma2[5000:]\n",
    "\n",
    "plt.figure(figsize = (6, 12))\n",
    "plt.subplot(211)\n",
    "plt.hist(np.array(mu_burn), bins = 30, )\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of mu\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.hist(np.array(sigma2_burn), bins = 30, )\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of sigma2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 872
    },
    "id": "sJ3kbSeGZ33D",
    "outputId": "7f192273-08db-418e-9d9a-f768be5d7d12",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# trace plot\n",
    "plt.figure(figsize = (10, 10))\n",
    "plt.subplot(211)\n",
    "plt.plot(np.linspace(5001, 10000, 5000), np.array(mu_burn))\n",
    "plt.xlabel(\"iter\")\n",
    "plt.ylabel(\"mu\")\n",
    "plt.title(\"Markov chain by Gibbs sampling\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(np.linspace(5001, 10000, 5000), np.array(sigma2_burn))\n",
    "plt.xlabel(\"iter\")\n",
    "plt.ylabel(\"sigma2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# MAP\n",
    "\n",
    "print(np.mean(mu_burn))\n",
    "print(np.mean(sigma2_burn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ioVIg3CraGkJ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example 3\n",
    "고속도로의 부분적 보수에 쓰이는 새로운 시멘트 혼합물이 굳을 때까지 걸리는 시간에 대한 1000번의 측정 자료가 있다. 이 시간 자료는 정규분포를 따른다고 가정할 때, 시간에 대한 평균과 분산을 Gibbs Sampling 방법으로 베이지안 추정을 해보자.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TY3p1Y92aGhn",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- $X_{1}, \\cdots, X_{n=1000} \\sim \\text { i.i.d } N\\left(\\mu, \\sigma^{2}\\right) $의 데이터가 존재 ($\\mu = 30(분), \\sigma^2 = 25(분)$)\n",
    "\n",
    "- 목적 : $\\mu, \\sigma^2$ 추정하는 것\n",
    "\n",
    "- 사전분포(noninformative) : $\\pi(\\mu) \\sim N(0, 10^2) \\;\\; \\& \\;\\; \\pi(\\sigma^2) \\sim IGamma(1, 5)$\n",
    "\n",
    "- 조건부 사후분포 :\n",
    " $$\\begin{aligned} \\mu | \\boldsymbol{X}, \\sigma^{2} & \\sim N\\left(\\frac{n \\overline{Y} \\sigma^{-2}}{n \\sigma^{-2}+ \\frac{1}{100}},\\; \\frac{1}{n \\sigma^{-2}+\\frac{1}{100}}\\right) \\\\ \\sigma^{2} | \\boldsymbol{X}, \\mu & \\sim \\text { InvGamma }\\left(\\frac{n}{2}+1,\\; \\frac{1}{2} \\sum_{i=1}^{n}\\left(X_{i}-\\mu\\right)^{2}+5\\right) \\end{aligned}$$\n",
    " \n",
    "- algorithm \n",
    "\n",
    "$$\n",
    "\\begin{array}{l}\n",
    "{\\text { [1] Initialize } \\left( \\mu^{(0)}, \\sigma^{2(0)}\\right)} \\\\\\\\\n",
    "{ \\text{For s=1 to N }}: \\\\\\\\\n",
    "{ \\text { [2] } \\mu^{(s)} \\sim N\\left(\\frac{n \\overline{Y} \\sigma^{-2(s-1)}}{n \\sigma^{-2(s-1)}+ \\frac{1}{100}},\\; \\frac{1}{n \\sigma^{-2(s-1)}+\\frac{1}{100}}\\right)}\\\\ \n",
    "{ \\text{ [3] }  \\sigma^{2(s)} \\sim \\text { IGamma }\\left(\\frac{n}{2}+1,\\; \\frac{1}{2} \\sum_{i=1}^{n}\\left(X_{i}-\\mu^{(s)}\\right)^{2}+5\\right)} \n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "(1) 초기값으로 $\\mu^{(0)} = 20(분), \\sigma^{2(0)} = 10(분)$로 놓고, $N = 10,000$개의 Gibbs sampler $\\left(\\left(\\mu^{(s)}, \\sigma^{2(s)}\\right), s=1, \\cdots, 10000\\right)$를 생성해보자.\n",
    "\n",
    "(2) 시간의 평균과 분산의 사후기댓값 추정량을 구해보자.\n",
    "\n",
    "(3) 시간의 평균과 분산 각각의 95% Credible Interval을 구해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CopP8kBkaQtP",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Gibbs sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 891
    },
    "id": "MOzMRmiAZ3xp",
    "outputId": "6f94e80d-7e0d-45c3-bfea-4f4c62b73344",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# 평균 30, 표준편차 5인 정규분포를 따르는 1000개의 데이터\n",
    "n = 1000\n",
    "obs = norm.rvs(30, 5, n)\n",
    "\n",
    "# 관측한 data의 histogram\n",
    "plt.figure(figsize = (6, 6))\n",
    "plt.hist(obs, bins = 20, )\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Distribution of 50 obs with $\\mu=95, \\sigma=1$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VVy4EpqEaVGj",
    "outputId": "e916fdae-255b-4f37-d6fb-35a8b844189b",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "xbar = obs.mean()\n",
    "xbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KJyeUy0kaU_b",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# setting initial values\n",
    "mu_init = 20\n",
    "sigma2_init = 10\n",
    "N = 10000\n",
    "\n",
    "# conditional distribution 함수 정의\n",
    "def mu_given_sigma2(s2):\n",
    "    # s2는 i-1번째 분산 값\n",
    "    mean = (n*xbar/s2 + 0/100)/(n/s2 + 1/100)\n",
    "    var = 1/(n/s2 + 1/100)\n",
    "    return norm.rvs(mean, np.sqrt(var))\n",
    "\n",
    "def sigma2_given_mu(m):\n",
    "    # m은 i번째 update된 mu값\n",
    "    alpha = n/2 + 1\n",
    "    beta = sum((obs-m)**2)/2 + 5\n",
    "    return invgamma.rvs(a = alpha, scale = beta, size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iyEav862aXK8",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "### Gibbs Sampling algorithm ###\n",
    "mu = []\n",
    "sigma2 = []\n",
    "mu_old = mu_init\n",
    "sigma2_old = sigma2_init\n",
    "\n",
    "for i in range(N):\n",
    "    mu_new = mu_given_sigma2(sigma2_old)\n",
    "    sigma2_new = sigma2_given_mu(mu_new)\n",
    "    mu_old = mu_new\n",
    "    sigma2_old = sigma2_new\n",
    "    mu.append(mu_new)\n",
    "    sigma2.append(sigma2_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "n0crNVBCaYYd",
    "outputId": "cb7af002-d05a-466f-8f3d-0097afce01db",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# 앞의 5000개는 burn-in period, 나머지 5000개로 정상분포 추정\n",
    "mu_burn = mu[5000:] \n",
    "sigma2_burn = sigma2[5000:]\n",
    "\n",
    "plt.figure(figsize = (10, 12))\n",
    "plt.subplot(211)\n",
    "plt.hist(np.array(mu_burn), bins = 30, )\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of $\\mu$\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.hist(np.array(sigma2_burn), bins = 30, )\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Histogram of $\\sigma^2$\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 872
    },
    "id": "Kxoa3souaZc9",
    "outputId": "2fc111fd-3e4f-42e9-a320-504abc76707d",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# trace plot\n",
    "plt.figure(figsize = (10, 10))\n",
    "plt.subplot(211)\n",
    "plt.plot(np.linspace(5001, 10000, 5000), np.array(mu_burn))\n",
    "plt.xlabel(\"iter\")\n",
    "plt.ylabel(\"mu\")\n",
    "plt.title(\"Markov chain by Gibbs sampling\")\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(np.linspace(5001, 10000, 5000), np.array(sigma2_burn))\n",
    "plt.xlabel(\"iter\")\n",
    "plt.ylabel(\"sigma2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o4fYZnV1abXQ",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qalmYpHAaccz",
    "outputId": "c2329a8d-42bf-4c93-85ed-e155e52b7834",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# MAP estimate\n",
    "print(round(np.array(mu_burn).mean(), 5)) \n",
    "print(round(np.array(sigma2_burn).mean(), 5)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YLFlEcS3ae6m",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Credible interval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FlayXYe4agA2",
    "outputId": "a9bd5abd-60da-45a1-84cc-be3c9e58bb77",
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# credible interval\n",
    "print(round(np.percentile(mu_burn, 2.5), 4))\n",
    "print(round(np.percentile(mu_burn, 97.5), 4))\n",
    "\n",
    "print(round(np.percentile(sigma2_burn, 2.5), 4))\n",
    "print(round(np.percentile(sigma2_burn, 97.5), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xkpPQLaGasI8",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Variational Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Coordinate Ascent Variational Inference(CAVI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- CAVI는 변분추론의 한 방법론으로, ELBO를 최대화하는 방향으로 학습을 진행합니다.\n",
    "- 이때, **mean-field** 근사를 가정합니다. 이는 모든 잠재변수들이 서로 독립이라는 가정입니다.\n",
    "\n",
    "\\begin{equation*}\n",
    "q_{\\theta}(z\\vert x) = \\prod_{i=1}^{K}q_{\\theta_i}(z_i\\vert x)\n",
    "\\end{equation*}\n",
    "\n",
    "- 이때, $q_{\\theta_i}(z_i\\vert x)$는 정규분포, 베르누이분포 등 다양한 분포를 가정합니다.\n",
    "- CAVI의 알고리즘은 다음과 같이 이루어집니다.\n",
    "\n",
    "1. Input: 혼합분포 $p(x,z)$, 관측 데이터 $x$, 잠재변수의 수 $K$\n",
    "2. Initialize: $q_{i}(z_i\\vert x)$ for $i=1,\\cdots,K$\n",
    "3. while ELBO has not conveerged do\n",
    "   1. for $i=1,\\cdots,K$ do\n",
    "   \n",
    "   \\begin{equation*}\n",
    "   q_{i}^{new}(z_i\\vert x) \\propto \\exp\\bigg(\\mathbb{E}_{-i}\\log p(x,\\mathbf{z})\\bigg)\n",
    "   \\end{equation*}\n",
    " \n",
    "   2. ELBO를 계산하고, 수렴 여부를 확인합니다.\n",
    "\n",
    "4. end\n",
    "5. Output: $q_(z\\vert x)=\\prod_{i=1}^{K}q_{i}(z_i\\vert x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 예시\n",
    "\n",
    "- 예시를 통해 CAVI를 이해해보도록 하겠습니다.\n",
    "- 예시에서는 다음과 같은 $K$-Gaussian Mixture Model을 가정합니다.\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{aligned}\n",
    "\\mu_j &\\sim \\mathcal{N}(0,1) \\quad \\text{for } j=1,\\cdots,K\\\\\n",
    "c_i &\\sim \\mathcal{U}(K) \\quad \\text{for } i=1,\\cdots,N\\\\\n",
    "x_i \\vert c_i, \\mu &\\sim \\mathcal{N}(c_i^T\\mu,1) \\quad \\text{for } i=1,\\cdots,N\n",
    "\\end{aligned}\n",
    "\\end{equation*}\n",
    "\n",
    "- 이때, $c_i$는 $K$차원의 one-hot vector입니다.\n",
    "- CAVI를 사용하기 위해, 다음과 같이 모수 $\\mu, c$를 잠재변수로 보고 mean-field 근사를 가정합니다.\n",
    "\n",
    "\\begin{equation*}\n",
    "q(\\mu,c) = q(\\mu\\vert m, s^2)q(c\\vert \\phi) = \\prod_{j=1}^{K}\\mathcal{N}(\\mu_j\\vert m_j, s_j^2)\\prod_{i=1}^{N}\\mathrm{Multi}(1, \\phi_i)\n",
    "\\end{equation*}\n",
    "\n",
    "- 여기서 $\\phi_i$는 확률 $p(c_i=j)=\\phi_{ij}$로 구성된 $K$차원 벡터입니다.\n",
    "- ELBO를 계산하면, 다음과 같습니다.\n",
    "\n",
    "\\begin{equation*}\n",
    "\\begin{aligned}\n",
    "\\mathrm{ELBO} &= \\mathbb{E}_q\\log p(x,z) - \\mathbb{E}_q\\log q(z)\\\\\n",
    "&\\propto \\sum_j -\\mathbb{E}_q\\bigg[\\frac{\\mu_j}{2\\sigma^2}\\bigg] + \\sum_i\\sum_j \\bigg[\\mathbb{E}_q c_{ij} - \\mathbb{E}_q\\bigg[-\\frac{(x_i-\\mu_j)^2}{2}\\bigg]\\bigg] \\\\\n",
    "&\\;\\;- \\sum_i\\sum_j \\mathbb{E}_q\\log\\phi_{ij} + \\sum_j \\frac{1}{2}\\log s_j^2\n",
    "\\end{aligned}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- CAVI의 알고리즘을 적용하면, 각 잠재변수(모수)들에 대해 다음과 같이 업데이트를 진행합니다.\n",
    "\n",
    "1. $\\phi_{ij}$\n",
    "\n",
    "\\begin{equation*}\n",
    "\\phi_{ij}^{new} \\propto \\exp\\bigg(-\\frac{1}{2}(m_j^2 + s_j^2) + x_i m_j\\bigg)\n",
    "\\end{equation*}\n",
    "\n",
    "2. $m_j$\n",
    "\n",
    "\\begin{equation*}\n",
    "m_j^{new} = \\frac{\\sum_i\\phi_{ij}x_i}{1+\\sum_i\\phi_{ij}}\n",
    "\\end{equation*}\n",
    "\n",
    "3. $s_j^2$\n",
    "\n",
    "\\begin{equation*}\n",
    "(s_j^2)^{new} = \\frac{1}{1+\\sum_i\\phi_{ij}}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "CAVI 알고리즘을 이용하여, 잠재변수의 학습이 이루어지는 과정을 살펴보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 데이터 생성하기\n",
    "- 여기서는 $K=3$으로 하고, 각 성분 분포에 대해 1000개의 데이터를 생성합니다.\n",
    "- `mu_true`에는 각 성분의 다음 모수가 저장됩니다.\n",
    "\n",
    "\\begin{equation*}\n",
    "\\mu_1 = 8.0, \\quad \\mu_2 = 1.2, \\quad \\mu_3 = -5.0\n",
    "\\end{equation*}\n",
    "\n",
    "- 아래는 데이터를 생성하고, 각 성분을 구분하기 위해 색을 다르게 표시한 히스토그램입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "K = 3\n",
    "mu_true = np.array([8.0, 1.2, -5.0])\n",
    "n_sample = 1000\n",
    "\n",
    "X = np.concatenate([np.random.normal(mu, 1.0, size=(n_sample, 1)) for mu in mu_true], axis=0).ravel()\n",
    "hue = np.concatenate([np.full(n_sample, i) for i in range(K)], axis=0).ravel()\n",
    "df = pd.DataFrame({\"x\": X, \"hue\": hue})\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.histplot(data=df, x=\"x\", hue=\"hue\", stat=\"density\", common_norm=False, bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### CAVI 알고리즘 적용하기\n",
    "\n",
    "CAVI 알고리즘을 적용하기 위해, 다음과 같이 `CAVI` 클래스를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class CAVI(object):\n",
    "    def __init__(self, X, K):\n",
    "        self.X = X\n",
    "        self.K = K\n",
    "        self.N = X.shape[0]\n",
    "\n",
    "    def initialize(self):\n",
    "        self.phi = np.random.dirichlet([1.0] * self.K, size=self.N)\n",
    "        self.m = np.random.randn(self.K)\n",
    "        self.s2 = np.ones(self.K) * np.random.random(self.K)\n",
    "        print(f\"Initial m: {self.m}, s2: {self.s2}\")\n",
    "\n",
    "    def ELBO(self):\n",
    "        t1 = np.log(self.s2) - self.m\n",
    "        t1 = t1.sum()\n",
    "        t2 = -0.5 * np.add.outer(self.X**2, self.s2 + self.m**2)\n",
    "        t2 += np.outer(self.X, self.m)\n",
    "        t2 -= np.log(self.phi)\n",
    "        t2 *= self.phi\n",
    "        t2 = t2.sum()\n",
    "\n",
    "        return t1 + t2\n",
    "\n",
    "    def update_phi(self):\n",
    "        t1 = np.outer(self.X, self.m)\n",
    "        t2 = -0.5 * self.m**2 - 0.5 * self.s2\n",
    "        exp = t1 + t2[np.newaxis, :]\n",
    "        self.phi = np.exp(exp)\n",
    "        self.phi /= self.phi.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    def update_m(self):\n",
    "        self.m = (self.phi*self.X[:, np.newaxis]).sum(0) * (1 + self.phi.sum(0))**(-1)\n",
    "        assert self.m.size == self.K\n",
    "\n",
    "    def update_s2(self):\n",
    "        self.s2 =(1 + self.phi.sum(0)) ** (-1)\n",
    "        assert self.s2.size == self.K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- 학습을 진행하기 이전에, 만들어둔 `CAVI` 클래스의 인스턴스를 생성합니다.\n",
    "- `initialize` 메소드를 통해, 잠재변수의 초기값을 설정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "cavi = CAVI(X, K)\n",
    "cavi.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "아래 코드는 학습 이전과 수렴 이후 모수에 대한 그래프를 그리기 위한 함수입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def plot(ax, i, elbo):\n",
    "    ax.clear()\n",
    "    sns.histplot(data=df, x=\"x\", hue=\"hue\", stat=\"density\", common_norm=False, bins=50, ax=ax, palette=\"Set2\")\n",
    "    bincount = np.bincount(cavi.phi.argmax(axis=1))\n",
    "\n",
    "    samples = np.concatenate([\n",
    "        np.random.normal(cavi.m[j], np.sqrt(cavi.s2[j]), size=(bincount[j], 1)) for j in range(K)\n",
    "    ]).ravel()\n",
    "\n",
    "    sns.kdeplot(samples, ax=ax, color=\"black\", linewidth=1.5, label=\"q(x)\")\n",
    "    ax.set_title(f\"Iteration {i} : ELBO = {elbo:.2f}\")\n",
    "    ax.legend()\n",
    "    ax.set_xlim(-10, 10)\n",
    "    ax.set_ylim(0, 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### 학습\n",
    "- 학습은 다음과 같이 반복문을 적용하여 진행합니다.\n",
    "- 가장 최근의 ELBO 값을 저장하여, 업데이트 이후 ELBO와의 차이가 $10^{-6}$보다 작아지면 학습을 종료합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "last_elbo = -np.inf\n",
    "fig, ax = plt.subplots(2, 3, figsize=(12, 8), sharey=True)\n",
    "\n",
    "for i in range(100):\n",
    "    if i == 0:\n",
    "        plot(ax[0,0], i, cavi.ELBO()) # Initial plot\n",
    "\n",
    "    cavi.update_phi()\n",
    "    cavi.update_m()\n",
    "    cavi.update_s2()\n",
    "\n",
    "    elbo = cavi.ELBO()\n",
    "\n",
    "    plot(ax[i//3, i%3], i, elbo)\n",
    "\n",
    "    if elbo - last_elbo < 1e-6:\n",
    "        break\n",
    "\n",
    "    last_elbo = elbo\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "학습된 결과를 확인해보면, 비교적 적은 반복횟수로도 초기 설정한 $\\mu_1, \\mu_2, \\mu_3$에 빠르게 수렴하는 것을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## PyMC\n",
    "- `pymc` 라이브러리는 MCMC 방법론을 이용하여 베이지안 추론을 수행하는 파이썬 라이브러리입니다.\n",
    "- 여기서는 `pymc` 라이브러리를 활용해 회귀분석을 진행해보고, 베이지안 신경망을 구성해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Example 1 revisited with PyMC\n",
    "\n",
    "앞선 예시 1번의 사후분포를 PyMC를 이용하여 추정해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# MH algorithm\n",
    "\n",
    "ex2 = pm.Model()\n",
    "\n",
    "with ex2:\n",
    "    # Cauchy 사전분포\n",
    "    mu = pm.Cauchy('mu', 0, 1)\n",
    "\n",
    "    # 관측값의 분포(가능도)\n",
    "    y = pm.Normal('y', mu=mu, sigma=1, observed=observation) # observed 값에 관측값 벡터를 넣어준다.\n",
    "\n",
    "    # Metropolis-Hastings 알고리즘\n",
    "    trace = pm.sample(10000, tune=1000, step=pm.Metropolis())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- `chain`의 개수는 default 값인 4개로 설정되었습니다.\n",
    "- Burn-in period는 1000번, Sample 10000번으로 MCMC를 진행되었고, 결과는 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Trace plot\n",
    "\n",
    "pm.plot_trace(trace)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# MAP estimate\n",
    "\n",
    "pm.find_MAP(model=ex2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bayesian Regression with PyMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "다음과 같은 회귀직선(True model)에서 데이터를 샘플링했다고 가정합니다.\n",
    "$$\n",
    "Y = -2.0 + 1.2X\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Data Generate\n",
    "\n",
    "n = 100\n",
    "true_beta_0 = -2.0\n",
    "true_beta_1 = 1.2\n",
    "\n",
    "x = np.linspace(0,1,n)\n",
    "y = true_beta_0 + true_beta_1 * x + np.random.normal(0, 0.2, n)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.scatter(x, y, label='data', s=10)\n",
    "plt.plot(x, true_beta_0 + true_beta_1 * x, c='r', label='$y = -2 + 1.2x$')\n",
    "plt.legend()\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Bayesian Linear Regression\n",
    "\n",
    "ex_linreg = pm.Model()\n",
    "\n",
    "with ex_linreg:\n",
    "    # 사전분포\n",
    "    beta_0 = pm.Normal('beta_0', mu=0, sigma=10)\n",
    "    beta_1 = pm.Normal('beta_1', mu=0, sigma=10)\n",
    "\n",
    "    # 관측값의 분포(가능도)\n",
    "    y = pm.Normal('y', mu=beta_0 + beta_1 * x, sigma=0.2, observed=y)\n",
    "\n",
    "    # MCMC 알고리즘\n",
    "    trace = pm.sample(10000, tune=1000, step=pm.Metropolis())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "pm.plot_trace(trace)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# MAP estimate\n",
    "\n",
    "pm.find_MAP(model=ex_linreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Bayesian Logistic Regression\n",
    "\n",
    "- `pymc` 라이브러리를 이용한 베이지안 로지스틱 회귀분석\n",
    "- `iris` 데이터를 이용해 로지스틱 회귀분석을 진행해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Feature : `sepal_length`, `sepal_width`\n",
    "- Class : `setosa`, `versicolor`\n",
    "- 모델은 다음과 같이 주어집니다.\n",
    "\n",
    "$$\n",
    "y = \\frac{1}{1+\\exp(-\\beta_0 - \\beta_1x_1 - \\beta_2x_2)}\n",
    "$$\n",
    "\n",
    "다음과 같이 uninformative prior를 가정합니다.\n",
    "\n",
    "$$\n",
    "\\beta_0,\\beta_1,\\beta_2 \\overset{iid}{\\sim} \\mathcal{N}(0, 10^2) \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "iris = sns.load_dataset('iris')\n",
    "iris = iris.loc[iris.species.isin(['setosa','versicolor']), ['sepal_length', 'sepal_width', 'species']]\n",
    "\n",
    "X = iris[iris.columns.drop('species')].to_numpy()\n",
    "\n",
    "X = StandardScaler().fit_transform(X)\n",
    "y = LabelEncoder().fit_transform(iris['species'])\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "주어진 데이터를 산점도로 표현하면 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the data\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "\n",
    "sns.scatterplot(x=X[:,0], y=X[:,1], hue=y, ax=ax)\n",
    "ax.set_xlabel('Sepal Length')\n",
    "ax.set_ylabel('Sepal Width')\n",
    "ax.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "`pymc`의 `Model` 모듈을 활용하여 다음과 같이 GLM을 구성할 수 있습니다.\n",
    "- Prior : 각 회귀계수에 대해($\\beta_0,\\beta_1,\\beta_2$) 정규사전분포 부여\n",
    "- Likelihood : 가능도함수(여기서는 이진 분류 문제이므로 베르누이 분포)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with pm.Model() as model:\n",
    "    # Priors\n",
    "    intercept = pm.Normal('Intercept', 0, sigma=100)\n",
    "    x1_coef = pm.Normal('sepal_length', 0, sigma=100)\n",
    "    x2_coef = pm.Normal('sepal_width', 0, sigma=100)\n",
    "\n",
    "    # Likelihood\n",
    "    likelihood = pm.invlogit(intercept + x1_coef*X[:,0] + x2_coef*X[:,1]) \n",
    "\n",
    "    # Bernoulli random variable\n",
    "    y_obs = pm.Bernoulli('y', p=likelihood, observed=y)\n",
    "    \n",
    "    trace = pm.sample(3000, tune=1000, chains=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "다음과 같이 `graphviz` 모듈을 이용하여 모델의 구조를 시각화할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "pm.model_to_graphviz(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "아래는 MAP 추정량을 활용한 결정경계를 그리는 코드입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# MAP estimate\n",
    "\n",
    "with model:\n",
    "    map_estimate = pm.find_MAP()\n",
    "\n",
    "print(map_estimate)\n",
    "\n",
    "# Plot the decision boundary\n",
    "\n",
    "xs = np.linspace(-3, 3, 100)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7, 7))\n",
    "\n",
    "ax.plot(xs, (-map_estimate['Intercept'] - map_estimate['sepal_length']*xs) / map_estimate['sepal_width'], color = 'r', label='MAP estimate')\n",
    "sns.scatterplot(x=X[:,0], y=X[:,1], hue=y, ax=ax)\n",
    "ax.set_xlabel('Sepal Length')\n",
    "ax.set_ylabel('Sepal Width')\n",
    "ax.legend(loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Comparison with scikit-learn\n",
    "\n",
    "- `sklearn` 라이브러리를 이용하여 로지스틱 회귀분석을 진행하고, `pymc`의 결과와 비교해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(X, y)\n",
    "\n",
    "# Estimate\n",
    "\n",
    "print(clf.intercept_, clf.coef_)\n",
    "\n",
    "# Plot the decision boundary\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7, 7))\n",
    "\n",
    "ax.plot(xs, (-clf.intercept_ - clf.coef_[0][0]*xs) / clf.coef_[0][1], color = 'b', label='Logistic Regression')\n",
    "ax.plot(xs, (-map_estimate['Intercept'] - map_estimate['sepal_length']*xs) / map_estimate['sepal_width'], color = 'r', label='MAP estimate')\n",
    "sns.scatterplot(x=X[:,0], y=X[:,1], hue=y, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bayesian Neural Network\n",
    "\n",
    "- 일반적인 신경망 구조는 $y=f(x;W)$로 표현되며, 파라미터 $W$를 주어진 데이터로부터 학습하는 것이 목표입니다.\n",
    "- 반면 베이지안 신경망은 파라미터 $W$의 사후분포를 추정하는 것이 목표입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, n_classes=2, random_state=0, n_clusters_per_class=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# plot tSNE\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "X_train_tsne = tsne.fit_transform(X_train)\n",
    "\n",
    "plt.figure(figsize=(7, 7))\n",
    "plt.scatter(X_train_tsne[y_train==0, 0], X_train_tsne[y_train==0, 1], label='Class 0', alpha=0.5)\n",
    "plt.scatter(X_train_tsne[y_train==1, 0], X_train_tsne[y_train==1, 1], label='Class 1', alpha=0.5)\n",
    "plt.title('tSNE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def construct_nn(ann_input, ann_output):\n",
    "    n_hidden = 32\n",
    "\n",
    "    # Initialize random weights between each layer\n",
    "    init_1 = np.random.normal(size=(X_train.shape[1], n_hidden))\n",
    "    init_2 = np.random.normal(size=(n_hidden, n_hidden))\n",
    "    init_out = np.random.normal(size=n_hidden)\n",
    "\n",
    "    coords = {\n",
    "        \"W1\": np.arange(n_hidden),\n",
    "        \"W2\": np.arange(n_hidden),\n",
    "        \"features\": np.arange(X_train.shape[1]),\n",
    "        # \"obs_id\": np.arange(X_train.shape[0]),\n",
    "    }\n",
    "    with pm.Model(coords=coords) as bnn:\n",
    "        ann_input = pm.Data(\"ann_input\", X_train, mutable=True, dims=(\"obs_id\", \"features\"))\n",
    "        ann_output = pm.Data(\"ann_output\", y_train, mutable=True, dims=\"obs_id\")\n",
    "\n",
    "        # Weights from input to hidden layer\n",
    "        weights_in_1 = pm.Laplace(\n",
    "            \"w_in_1\", mu=0, b=1, initval=init_1, dims=(\"features\", \"W1\")\n",
    "        )\n",
    "\n",
    "        # Weights from 1st to 2nd layer\n",
    "        weights_1_2 = pm.Laplace(\n",
    "            \"w_1_2\", mu=0, b=1, initval=init_2, dims=(\"W1\", \"W2\")\n",
    "        )\n",
    "\n",
    "        # Weights from hidden layer to output\n",
    "        weights_2_out = pm.Normal(\"w_2_out\", 0, sigma=1, initval=init_out, dims=\"W2\")\n",
    "\n",
    "        # Build neural-network using tanh activation function\n",
    "        act_1 = pm.math.maximum(0,pm.math.dot(ann_input, weights_in_1))\n",
    "        act_2 = pm.math.maximum(0, pm.math.dot(act_1, weights_1_2))\n",
    "        act_out = pm.math.sigmoid(pm.math.dot(act_2, weights_2_out))\n",
    "\n",
    "        # Binary classification -> Bernoulli likelihood\n",
    "        out = pm.Bernoulli(\n",
    "            \"out\",\n",
    "            act_out,\n",
    "            observed=ann_output,\n",
    "            total_size=y_train.shape[0],  # IMPORTANT for minibatches\n",
    "            dims=\"obs_id\",\n",
    "        )\n",
    "    return bnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "`pm.ADVI` 클래스를 이용하면, mean-field 근사를 가정한 변분추론을 수행할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "BNN = construct_nn(X_train, y_train)\n",
    "\n",
    "with BNN:\n",
    "    advi = pm.ADVI()\n",
    "    approx = pm.fit(30000, method=advi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Plot ELBO\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(approx.hist)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Test 데이터에 대해 예측을 수행하고, 실제값과 비교해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with BNN:\n",
    "    trace = approx.sample(1000)\n",
    "\n",
    "# Test set\n",
    "\n",
    "with BNN:\n",
    "    pm.set_data({\"ann_input\": X_test, \"ann_output\": y_test})\n",
    "    ppc = pm.sample_posterior_predictive(trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "BNN에서의 예측은, 각 테스트 데이터에 대해 여러 사후분포 샘플과(여기서는 1000개) 여러 chain(여기서는 4개)에 대한 샘플을 이용하여, 이들의 평균을 예측값으로 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "ppc.posterior_predictive['out'].mean(('chain', 'draw'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, np.where(ppc.posterior_predictive['out'].mean(('chain', 'draw')) > 0.5, 1, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Comparison with Logistic\n",
    "\n",
    "로지스틱 회귀분석과 베이지안 신경망의 결과를 비교해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(random_state=0).fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, y_pred)\n",
    "\n",
    "# 0.96"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "정확도 비교 결과 BNN이 더 높은 정확도(99%>96%)를 보이는 것을 확인할 수 있습니다."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
